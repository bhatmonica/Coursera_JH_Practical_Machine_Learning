---
title: "Practical Machine Learning Course Project "
author: "Monica Bhat"
date: "June 12, 2016"
output: html_document
---

These is a project submitted during a homework assignment of Coursera's MOOC <b>Practical Machine Learning</b> from <b>Johns Hopkins Bloomberg School of Public Health</b>.  

## Background  

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: 
[http://groupware.les.inf.puc-rio.br/har].

##Data

The training data for this project are available here:

[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv]

The test data are available here:

[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv]

The data for this project come from this source: [http://groupware.les.inf.puc-rio.br/har]. 

## Replicating Results of this Experiment

Please install packages listed below and use the same seed,
To install, for instance, the `caret` package in R, run this command: `install.packages("caret")`.  
To avoid reinstall, run the following command:
`if("caret" %in% rownames(installed.packages()) == FALSE) {install.packages("caret")} ;`

The following Libraries were used in this project, and should be loaded in working environment.  

```{r warning=FALSE, error=FALSE}

library(rattle)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
library(randomForest)
library(RColorBrewer)

```

##Set Seed

Load the same seed with the following line of code:  
```{r warning=FALSE, error=FALSE}
set.seed(12345)
```  

## Load Data  

Read the datafiles from URL provided in project statement and load the dataframes for training and testing datasets.

```{r warning=FALSE, error=FALSE}

trainLocation <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testLocation <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(url(trainLocation), na.strings=c("NA","#DIV/0!",""))
testingData <- read.csv(url(testLocation), na.strings=c("NA","#DIV/0!",""))

```  

## Data Cleaning Steps  

Clean the dataset and get rid of observations with missing values as well as redundant  variables.  

 
```{r warning=FALSE, error=FALSE}
NZV <- nearZeroVar(trainingData, saveMetrics = TRUE)
head(NZV, 20)
trainingClean <- trainingData[, !NZV$nzv]
testingClean <- testingData[, !NZV$nzv]
dim(trainingClean)
dim(testingClean)

unwanted_col <- grepl("^X|timestamp|user_name", names(trainingClean))
training <- trainingClean[, !unwanted_col]
testing <- testingClean[, !unwanted_col]

dim(training)
dim(testing)

training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(training)) == 0]

```

## Garbage Collection 

```{r warning=FALSE, error=FALSE}
rm(trainingData)
rm(testingData)
rm(trainingClean)
rm(testingClean)

```

### Correlation Matrix of features in the Training Data.  
```{r warning=FALSE, error=FALSE}
corrplot(cor(training[, -length(names(training))]), method = "color", tl.cex = 0.5)

```

## Data Partitioning  
Split the training set into a training data set (70%) and a validation data set (30%). Validation data set is used to conduct cross validation.  

```{r warning=FALSE, error=FALSE}
set.seed(12345) 
inTrain <- createDataPartition(training$classe, p = 0.70, list = FALSE)
validation <- training[-inTrain, ]
training <- training[inTrain, ]

```

## Data Modelling  

### Decision Tree Algorithm 

Use Decision Tree algorithm for predictive modeling.

```{r warning=FALSE, error=FALSE}
modelTree <- rpart(classe ~ ., data = training, method = "class")
prp(modelTree)
predictTree <- predict(modelTree, validation, type = "class")
confusionMatrix(validation$classe, predictTree)
accuracy <- postResample(predictTree, validation$classe)
ose <- 1 - as.numeric(confusionMatrix(validation$classe, predictTree)$overall[1])

```
The Estimated Accuracy of the Decision Tree Algorithm is `r accuracy[1]*100`% and the Estimated Out-of-Sample Error is `r ose*100`%.  

### Random Forest

Use Random Forest for a predictive model since it automatically selects key variables and is robust to correlated covariates & outliers in general.  

```{r warning=FALSE, error=FALSE}
modelRF <- randomForest(classe ~. , data=training)
modelRF
predictRF <- predict(modelRF, validation)
confusionMatrix(validation$classe, predictRF)
accuracy <- postResample(predictRF, validation$classe)
ose <- 1 - as.numeric(confusionMatrix(validation$classe, predictRF)$overall[1])
predict(modelRF, testing[, -length(names(testing))])
```

The Estimated Accuracy of the Random Forest Algorithm is `r accuracy[1]*100`% and the Estimated Out-of-Sample Error is `r ose*100`%. The Random forest accuracy is much better than decision tree as expected. 

## Predicting Test Data Set Results  
Now, we apply the Random Forest model to the testing data set downloaded from the project locations. 

```{r warning=FALSE, error=FALSE}
predict(modelRF, testing[, -length(names(testing))])
```

## Generating Files for Assignment Submission

Function to generate files with predictions to submit for assignment. 

```{r warning=FALSE, error=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, col.names = FALSE)
  }
}
```

Generating the Files.  
```{r warning=FALSE, error=FALSE}
pml_write_files(predict(modelRF, testing[, -length(names(testing))]))
```

